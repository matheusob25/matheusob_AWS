## Esse Ã© o script para os jsons que eu trouxe nessa sprint pois senti que estavam faltando dados
## Jsons TMDB (Detalhes de atores e diretores de cada filme)

import sys
import os 
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.sql import SparkSession 
from pyspark.sql.functions import * 

## @params: [JOB_NAME]
args = getResolvedOptions(sys.argv, ['JOB_NAME','S3_INPUT_PATH1','S3_INPUT_PATH2','S3_INPUT_PATH3','S3_INPUT_PATH4','S3_INPUT_PATH5','S3_INPUT_PATH6','S3_OUTPUT_PATH'])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)
sf1 = args['S3_INPUT_PATH1']
sf2 = args['S3_INPUT_PATH2']
sf3 = args['S3_INPUT_PATH3']
sf4 = args['S3_INPUT_PATH4']
sf5 = args['S3_INPUT_PATH5']
sf6 = args['S3_INPUT_PATH6']
target_path = args['S3_OUTPUT_PATH']

spark_df = spark.read.json(sf1)
spark_df = spark_df.withColumn("id_filme", lit(120))

df2 = spark.read.json(sf2)
df2 = df2.withColumn("id_filme", lit(121))

df3 = spark.read.json(sf3)
df3 = df3.withColumn("id_filme", lit(122))

df4 = spark.read.json(sf4)
df4 = df4.withColumn("id_filme", lit(49051))

df5 = spark.read.json(sf5)
df5 = df5.withColumn("id_filme", lit(57158))

df6 = spark.read.json(sf6)
df6 = df6.withColumn("id_filme", lit(122917))


dfs = [df2, df3, df4, df5, df6]
for d in dfs:
    spark_df = spark_df.union(d)


spark_df = spark_df.repartition(1)

spark_df.write.parquet(target_path, mode="append")
job.commit()
